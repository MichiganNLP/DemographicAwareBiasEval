{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 \n",
    "import argparse\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from transformers import BertConfig, BertForSequenceClassification, AdamW, get_scheduler\n",
    "# from datasets import load_metric\n",
    "from transformers import TrainingArguments\n",
    "# from transformers import Trainer\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff1 =  pd.read_csv(\"Female_aligned_data.csv\")\n",
    "dff2 =  pd.read_csv(\"Male_aligned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([dff1, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "clean_txt = []\n",
    "for w in range(len(df['0'])):\n",
    "    desc = df['0'][w].lower()\n",
    "    desc = re.sub('[^a-zA-Z]', ' ', desc) # punc\n",
    "    desc=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",desc) #tags\n",
    "    desc=re.sub(\"(\\\\d|\\\\W)+\",\" \",desc)\n",
    "    clean_txt.append(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean'] = clean_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['clean']\n",
    "labels_train = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertTokenizer, BertModel\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Models/\")\n",
    "model = BertMLM.from_pretrained(\"Models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = []\n",
    "attention_masks_train = []\n",
    "\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                    \n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 512,           \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,  \n",
    "                        return_tensors = 'pt',     \n",
    "                        truncation=True\n",
    "                   )\n",
    "    \n",
    "    input_ids_train.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    attention_masks_train.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids_train = torch.cat(input_ids_train, dim=0)\n",
    "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
    "labels_train = torch.tensor(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "train_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset), \n",
    "            batch_size = batch_size,\n",
    "            \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentence embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h1.remove()\n",
    "h1 = model.encoder.layer[11].output.dropout.register_forward_hook(get_features('feats'))\n",
    "# h1 = model.bert.pooler.register_forward_hook(get_features('feats'))\n",
    "# h1 = model.bert.embeddings.register_forward_hook(get_features('feats'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PREDS = []\n",
    "FEATS = []\n",
    "cnt = 0\n",
    "# placeholder for batch features\n",
    "features = {}\n",
    "k = 0\n",
    "# loop through batches\n",
    "\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    input_ids = batch[0].to(device, dtype=torch.long)\n",
    "    mask = batch[1].to(device, dtype=torch.long)\n",
    "    labels = batch[2].to(device, dtype=torch.long)\n",
    "    print(cnt)\n",
    "\n",
    "    preds = model(input_ids=input_ids, attention_mask=mask)\n",
    "    FEATS.append(features['feats'].cpu().numpy())\n",
    "    cnt = cnt + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "FEATS_encoder_0 = np.concatenate(FEATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('- feats shape:', FEATS_encoder_0.shape)\n",
    "feats_enc = np.mean(FEATS_encoder_0, axis = (1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(feats_enc).to_csv(\"embeds_1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
